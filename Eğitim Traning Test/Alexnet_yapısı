"""
Kütüphane versiyonları;
tensorflow == 2.6.0 (pip install tensorflow-gpu==2.6.0)
keras == 2.6.0 (pip install keras==2.6.0)
"""

import tensorflow as tf
import numpy as np
import os
from tqdm import tqdm
import cv2
from datetime import datetime
from random import shuffle
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import sklearn
print(sklearn._version_)

tf.compat.v1.disable_eager_execution()

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

#%% değiştirilebilir değerler

image_width = 227
image_height = 227
learning_rate = 1e-4
batch_size = 16
epoch = 500


train_path = "C:\\Users\\AKTS\\Desktop\\food-101\\food-101\\images_227_227"


#%% klasörden veri okuma ve etiketleme
       
def one_hot(array):
    unique, inverse = np.unique(array, return_inverse=True)
    onehot = np.eye(unique.shape[0])[inverse]
    return onehot

#train_or_test_folder_name = test ya da train ya da validation klasörünün sadece ismi
#dataset_type_name = open ya da close olan klasörün ismi
def dataset_load(path, start_index=None, end_index=None):
    dataset_load = []
    images_ds = []
    string_labels = []
    X_train = []
    y_train = []
    X_test = []
    y_test = []
    X_valid = []
    y_valid = []
    i = 0
    for folder in tqdm(os.listdir(path)): 
        images_ds = []
        string_labels = []
        for image in tqdm(os.listdir(path+"/"+folder)):
            path_image = os.path.join(path+'/'+folder, image)
            image_data = cv2.imdecode(np.fromfile(path_image, np.uint8), -1)
            if len(image_data.shape) == 2:
                print("path : {}".format(path_image))
            images_ds.append(np.array(image_data))        
            string_labels.append(folder)
            # dataset_load.append([np.array(image_data), folder])
            i = i + 1
            
        # label_train = one_hot(string_labels)
        X_train2, X_rem2, y_train2, y_rem2 = train_test_split(images_ds, string_labels, train_size=0.7)
        X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_rem2,y_rem2, test_size=0.5)
        
        for element in range(0, len(X_train2)):
            X_train.append(np.array(X_train2[element]))
            y_train.append(y_train2[element])
            
            
        for element in range(0, len(X_test2)):
            X_test.append(np.array(X_test2[element]))
            y_test.append(y_test2[element])

        for element in range(0, len(X_valid2)):
            X_valid.append(np.array(X_valid2[element]))
            y_valid.append(y_valid2[element])
            
        
        # X_train.append(X_train2)    
        # y_train.append(np.array(y_train2)) 
        # X_test.append(X_test2)    
        # y_test.append(np.array(y_test2)) 
        # X_valid.append(X_valid2) 
        # y_valid.append(np.array(y_valid2)) 

    
    return X_train, y_train, X_test, y_test, X_valid, y_valid
    
x_train, y_train, x_test, y_test, x_valid, y_valid = dataset_load(train_path)

# def one_hot(array):
#     unique, inverse = np.unique(array, return_inverse=True)
#     onehot = np.eye(unique.shape[0])[inverse]
#     return onehot

#return dataset_load
# images_train = np.array([i[0] for i in train])
# , random_state=42
# string_labels = [i[1] for i in train]

y_train = one_hot(y_train)
y_test = one_hot(y_test)
y_valid = one_hot(y_valid)


x_train = np.array(x_train)
x_test = np.array(x_test)
x_valid = np.array(x_valid)

#%% Model oluşturma ve eğitim

model = tf.keras.models.Sequential([
    
    #layer 1
    tf.keras.layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(image_width, image_height, 3)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(3, strides=(2, 2)),
    
    #layer 2
    tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(3, strides=(2, 2)),
    
    #layer3
    tf.keras.layers.Conv2D(384, (3, 3), strides=(1, 1), activation='relu', padding='same'),
    tf.keras.layers.BatchNormalization(),

    #loyer 4
    tf.keras.layers.Conv2D(384, (3, 3), strides=(1, 1), activation='relu', padding='same'),
    tf.keras.layers.BatchNormalization(),

    #layer 5    
    tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(3, strides=(2, 2)),
    
    #flatten layer öncesi düzenleme
    tf.keras.layers.Flatten(),
    
    #flatten layer 1
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    
    #flatten layer 2
    tf.keras.layers.Dense(1000, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    
    tf.keras.layers.Dense(len(y_train[1]), activation='softmax')
    
    ])

callback = [tf.keras.callbacks.EarlyStopping(monitor="val_loss", min_delta=0.0001, patience=20, restore_best_weights=True)] #min delta değişim olması gereken değer

#optimizer = SGD(lr=1e-4, decay=1e-06, momentum=0.9)
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=1e-05)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

start_train = datetime.now()
history = model.fit(np.array(x_train), y_train, batch_size=batch_size, epochs=epoch, shuffle=True, 
          validation_data=(np.array(x_test), y_valid))

#model.fit(np.array(images_train), np.array(label_train), batch_size=batch_size, epochs=epoch, shuffle=True, 
          #validation_data=(np.array(images_validate), np.array(label_validate)), callbacks=callback)
                                                                                                    
end_train = datetime.now()

#%% eğitim adımlarını grafikte gösterme

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='lower left')
plt.show()

print("toplam eğitim süresi : {}".format(end_train-start_train))

#%% model test
start_test = datetime.now()
result = model.evaluate(np.array(x_test), np.array(y_test), verbose=0, batch_size=1)
end_test = datetime.now()
print("Toplam Test süresi : {}".format(end_test-start_test))

print("test loss : ", result[0])
print("test accuracy : ", result[1])

# model.summary()

#%% consufion matrix oluşturma 
predict = model.predict(x_test, batch_size=8)
correct_pred = np.argmax(predict, 1) == np.argmax(y_test, 1)

y_predict = (predict > 0.5)

cm = confusion_matrix(np.argmax(y_test, 1), np.argmax(y_predict, 1))

#aşağı kısım görsel olarak plot çıktısı verir confusion matrix için
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(cm)
for (i, j), z in np.ndenumerate(cm):    #burada oluşturulan plot matris görüntüsünde her bir hücrenin içerisine değerler atanıyor.
    ax.text(j, i, '{}'.format(z), ha='center', va='center')
plt.title("confusion matrix classifier")
fig.colorbar(cax)  
ax.set_xlabel("Predicted labels")
ax.set_ylabel("True Labels")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
